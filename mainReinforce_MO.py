# -*- coding: utf-8 -*-
"""
Created on Fri Oct 18 19:39:49 2019

@author: Tiago
"""
from reinforce_MO import Reinforcement
from keras.models import Sequential
from model import Model  
from prediction import Predictor
import numpy as np
from utils import *

config_file = 'configReinforce.json' # Configuration file 
        
def main():
    # load configuration file
    configReinforce,exp_time=load_config(config_file)
    
    # Load Generator object
    generator_model = Sequential()
    generator_model=Model(configReinforce)
    generator_model.model.load_weights(configReinforce.model_name_unbiased)

     # Load the Predictor of KOR affinity object 
    predictor = Predictor(configReinforce,'kor')

    # Initialize lists to evaluate the model
    difs_kor = [] # List with the differences between the averages of KOR affinity distributions (G_0 and G_optimized)
    difs_qed = []
    divs = [] # List with the internal diversities of the G_optimized generated molecules 
    perc_valid = [] # List with the % of valid SMILES generated by G_optimized
    uniqs = [] # List with the % of unique SMILES strings 

    # Create Reinforcement Learning (RL) object
    RL_obj = Reinforcement(generator_model, predictor, configReinforce)
    
    
    RL_obj.drawMols()
     # SMILES generation test with the unbiased Generator
    smiles_original, prediction_original_kor,prediction_original_qed,valid,unique = RL_obj.test_generator(configReinforce.n_to_generate,0,True)

    # Step of RL training  
    cumulative_rewards_qed,cumulative_rewards_kor,cumulative_rewards,previous_weights = RL_obj.policy_gradient()
    
    # SMILES generation test after 60 RL training iterations 
    smiles_iteration85,prediction_iteration85_kor,prediction_iteration85_qed,valid,unique = RL_obj.test_generator(configReinforce.n_to_generate,85, False)
   
    # Plot the changes in the distribution after applying RL
    plot_evolution(prediction_original_kor,prediction_iteration85_kor,'kor')
    plot_evolution(prediction_original_qed,prediction_iteration85_qed,'qed')
#    
#    # Other way of evaluating the differences before and after applying RL. It 
#    # evaluates the internal diversity, validity and uniqueness
    for k in range(20):
        print("\nGeneration test:" + str(k))
        dif_qed,dif_kor,valid,div,unique = RL_obj.compare_models(configReinforce.n_to_generate,True)
        difs_kor.append(dif_kor)
        difs_qed.append(dif_qed)
        divs.append(div)
        perc_valid.append(valid)
        uniqs.append(unique)
        
    print("\nMean value difference for KOR: " + str(np.mean(difs_kor)))
    print("Mean value difference for QED: " + str(np.mean(difs_qed)))
    print("Mean value diversity: " + str(np.mean(divs)))
    print("Mean value validity: " + str(np.mean(perc_valid)))
    print("Mean value uniqueness: " + str(np.mean(uniqs)))
if __name__ == '__main__':
    main()